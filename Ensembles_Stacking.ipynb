{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ensembles_Stacking.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKcOxZF5cQ_i",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 579
        },
        "outputId": "0f25ca23-d093-4acc-8bdc-d529cc289f32"
      },
      "source": [
        "!pip install pandas==0.19.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pandas==0.19.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/21/93/5b5c84a92db8bdd9748960003bcfed3df173e1d3f0cca393512ea98d14cb/pandas-0.19.0.tar.gz (8.3MB)\n",
            "\u001b[K     |████████████████████████████████| 8.3MB 2.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2 in /usr/local/lib/python3.6/dist-packages (from pandas==0.19.0) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas==0.19.0) (2018.9)\n",
            "Requirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.6/dist-packages (from pandas==0.19.0) (1.18.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2->pandas==0.19.0) (1.15.0)\n",
            "Building wheels for collected packages: pandas\n",
            "  Building wheel for pandas (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pandas: filename=pandas-0.19.0-cp36-cp36m-linux_x86_64.whl size=15750807 sha256=cb9678c3dc1a5474e1082067d3decf135b645d6d597da929db4bae83d015b745\n",
            "  Stored in directory: /root/.cache/pip/wheels/71/12/f8/3a27ff70387254d0eb0050e904b1f52d42d9940fdf70ecff11\n",
            "Successfully built pandas\n",
            "\u001b[31mERROR: xarray 0.15.1 has requirement pandas>=0.25, but you'll have pandas 0.19.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: seaborn 0.11.0 has requirement pandas>=0.23, but you'll have pandas 0.19.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: plotnine 0.6.0 has requirement pandas>=0.25.0, but you'll have pandas 0.19.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: pandas-datareader 0.9.0 has requirement pandas>=0.23, but you'll have pandas 0.19.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: mizani 0.6.0 has requirement pandas>=0.25.0, but you'll have pandas 0.19.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement pandas~=1.1.0; python_version >= \"3.0\", but you'll have pandas 0.19.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fbprophet 0.7.1 has requirement pandas>=1.0.4, but you'll have pandas 0.19.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: cufflinks 0.17.3 has requirement pandas>=0.19.2, but you'll have pandas 0.19.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: catboost 0.24.2 has requirement pandas>=0.24.0, but you'll have pandas 0.19.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: pandas\n",
            "  Found existing installation: pandas 1.1.2\n",
            "    Uninstalling pandas-1.1.2:\n",
            "      Successfully uninstalled pandas-1.1.2\n",
            "Successfully installed pandas-0.19.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pandas"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtcnZpdlcZ4e"
      },
      "source": [
        "import pandas as pd\n",
        "pd.__version__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGnahSQLaR1u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 690
        },
        "outputId": "cbfc3e02-98c5-44ee-806e-6ffa5e9a4ac8"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import preprocessing\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import drive\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.utils import resample\n",
        "!pip install mlxtend\n",
        "import imblearn\n",
        "!pip install catboost\n",
        "!pip install xgboost\n",
        "!pip install lightgbm\n",
        "from numpy import loadtxt\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import f1_score, classification_report\n",
        "\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict, StratifiedKFold, RepeatedStratifiedKFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.svm import SVC\n",
        "import lightgbm as lgb\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB \n",
        "from mlxtend.classifier import StackingCVClassifier\n",
        "from sklearn.linear_model import RidgeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "#catboost\n",
        "\n",
        "from catboost import CatBoostClassifier\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mlxtend in /usr/local/lib/python3.6/dist-packages (0.14.0)\n",
            "Requirement already satisfied: matplotlib>=1.5.1 in /usr/local/lib/python3.6/dist-packages (from mlxtend) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from mlxtend) (1.18.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from mlxtend) (50.3.0)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.6/dist-packages (from mlxtend) (0.22.2.post1)\n",
            "Requirement already satisfied: pandas>=0.17.1 in /usr/local/lib/python3.6/dist-packages (from mlxtend) (1.1.2)\n",
            "Requirement already satisfied: scipy>=0.17 in /usr/local/lib/python3.6/dist-packages (from mlxtend) (1.4.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.5.1->mlxtend) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.5.1->mlxtend) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.5.1->mlxtend) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.5.1->mlxtend) (2.8.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.18->mlxtend) (0.16.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.17.1->mlxtend) (2018.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib>=1.5.1->mlxtend) (1.15.0)\n",
            "Requirement already satisfied: catboost in /usr/local/lib/python3.6/dist-packages (0.24.2)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.18.5)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from catboost) (1.15.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.6/dist-packages (from catboost) (4.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from catboost) (3.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from catboost) (1.4.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->catboost) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->catboost) (2.8.1)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly->catboost) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (2.4.7)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.6/dist-packages (0.90)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from xgboost) (1.18.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from xgboost) (1.4.1)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.6/dist-packages (2.2.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from lightgbm) (1.18.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from lightgbm) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from lightgbm) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->lightgbm) (0.16.0)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlY5sr4vaa3h"
      },
      "source": [
        "# Stackingcvclassifier\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict, StratifiedKFold, RepeatedStratifiedKFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.svm import SVC\n",
        "import lightgbm as lgb\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB \n",
        "from mlxtend.classifier import StackingCVClassifier\n",
        "from sklearn.linear_model import RidgeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "#catboost\n",
        "\n",
        "from catboost import CatBoostClassifier\n",
        "training_data = pd.read_excel('/content/drive/My Drive/ML_Hackathon/ML_Hackathon/train.xlsx')\n",
        "training_data.drop('ID', axis = 1, inplace = True)\n",
        "training_data.rename(columns={'Number_Weeks_does_not used': 'Number_Weeks_does_not_used'}, inplace=True)\n",
        "\n",
        "X = training_data.drop(\"Crop_status\", axis=1)\n",
        "y = training_data[\"Crop_status\"]\n",
        "X.fillna(X[\"Number_of_Weeks_Used\"].median(), axis = 1, inplace = True)\n",
        "\n",
        "X[\"Number_of_Weeks_Used\"] = X[\"Number_of_Weeks_Used\"].astype(np.int) \n",
        "\n",
        "X=pd.get_dummies(X, columns=[\"Crop\",\"Soil\", \"Season\"])\n",
        "\n",
        "X.drop('Soil_clay', axis = 1, inplace = True)\n",
        "X.drop('Crop_Feed', axis = 1, inplace = True)\n",
        "X.drop('Season_3', axis = 1, inplace = True)\n",
        "\n",
        "\n",
        "test_df_off = pd.read_excel('/content/drive/My Drive/ML_Hackathon/ML_Hackathon/test.xlsx')\n",
        "test_df_off.drop('ID', axis = 1, inplace = True)\n",
        "test_df_off.rename(columns={'Number_Weeks_does_not used': 'Number_Weeks_does_not_used'}, inplace=True)\n",
        "\n",
        "\n",
        "test_df_off.fillna(test_df_off[\"Number_of_Weeks_Used\"].median(), axis = 1, inplace = True)\n",
        "test_df_off[\"Number_of_Weeks_Used\"] = test_df_off[\"Number_of_Weeks_Used\"].astype(np.int) \n",
        "test_df_off=pd.get_dummies(test_df_off, columns=[\"Crop\",\"Soil\", \"Season\"])\n",
        "test_df_off.drop('Soil_clay', axis = 1, inplace = True)\n",
        "test_df_off.drop('Crop_Feed', axis = 1, inplace = True)\n",
        "test_df_off.drop('Season_3', axis = 1, inplace = True)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, stratify = y)\n",
        "\n",
        "\n",
        "\n",
        "grid_parameters = [\n",
        "    { # XGBoost\n",
        "        'n_estimators': [400, 700, 1000],\n",
        "        'colsample_bytree': [0.7, 0.8],\n",
        "        'max_depth': [15,20,25],\n",
        "        'reg_alpha': [1.1, 1.2, 1.3],\n",
        "        'reg_lambda': [1.1, 1.2, 1.3],\n",
        "        'subsample': [0.7, 0.8, 0.9]\n",
        "    },\n",
        "    { # LightGBM\n",
        "        'n_estimators': [400, 700, 1000],\n",
        "        'learning_rate': [0.12],\n",
        "        'colsample_bytree': [0.7, 0.8],\n",
        "        'max_depth': [4],\n",
        "        'num_leaves': [10, 20],\n",
        "        'reg_alpha': [1.1, 1.2],\n",
        "        'reg_lambda': [1.1, 1.2],\n",
        "        'min_split_gain': [0.3, 0.4],\n",
        "        'subsample': [0.8, 0.9],\n",
        "        'subsample_freq': [10, 20]\n",
        "    }, \n",
        "    { # Random Forest\n",
        "        'max_depth':[3, 5, 10, 13], \n",
        "        'n_estimators':[100, 200, 400, 600, 900],\n",
        "        'max_features':[2, 4, 6, 8, 10]\n",
        "    },\n",
        "    # Support Vector Classifier parameters \n",
        "    {\n",
        "    'kernel' : 'linear',\n",
        "    'C' : 0.025\n",
        "    },\n",
        "    # AdaBoost parameters\n",
        "{\n",
        "    'n_estimators': 500,\n",
        "    'learning_rate' : 0.75\n",
        "}\n",
        "\n",
        "]\n",
        "\n",
        "#meta\n",
        "xgb = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=0.9, colsample_bynode= 1, colsample_bytree=1, \n",
        "                    eval_metric='mlogloss', gamma= 2.8, interaction_constraints='', learning_rate=0.01, max_delta_step=1, \n",
        "                    max_depth= 4, min_child_weight=4.2, missing=None, n_estimators=1000, n_jobs=0, nthread=None, num_class=3, \n",
        "                    num_parallel_tree=1, objective='multi:softprob', random_state=0, reg_alpha=0.5, reg_lambda=1, scale_pos_weight=None, \n",
        "                    seed=None, silent=None, subsample=0.7, tree_method='exact', validate_parameters=1, verbosity=1) \n",
        "\n",
        "\n",
        "lgbm = lgb.LGBMClassifier(max_depth = 4, n_estimators = 1000, is_unbalance = True)\n",
        "\n",
        "cat = CatBoostClassifier(\n",
        "    max_depth = 5,\n",
        "    iterations=888, \n",
        "    learning_rate=0.07, \n",
        "    loss_function='MultiClass',\n",
        "    classes_count = 3,\n",
        "    cat_features=[0,1,2,3,4,5,6,7,8],\n",
        "    leaf_estimation_method= 'Newton',\n",
        "    random_strength = 0.9,\n",
        "    boosting_type = 'Ordered',\n",
        "    sampling_frequency= 'PerTreeLevel',\n",
        "    l2_leaf_reg = 2,\n",
        "    random_state = 42\n",
        "\n",
        ")\n",
        "\n",
        "cat_fast = CatBoostClassifier(\n",
        "    max_depth = 5,\n",
        "    iterations=888, \n",
        "    learning_rate=0.5, \n",
        "    loss_function='MultiClass',\n",
        "    classes_count = 3,\n",
        "    cat_features=[0,1,2,3,4,5,6,7,8],\n",
        "    leaf_estimation_method= 'Newton',\n",
        "    random_strength = 0.9,\n",
        "    boosting_type = 'Ordered',\n",
        "    sampling_frequency= 'PerTreeLevel',\n",
        "    l2_leaf_reg = 2,\n",
        "    random_state = 42\n",
        "\n",
        ")\n",
        "lr = LogisticRegression(C = 0.5, class_weight = 'balanced', multi_class = 'multinomial') # smaller C, more reg\n",
        "rf = RandomForestClassifier(max_depth = 4, n_estimators= 500, max_features='sqrt', class_weight = \"balanced\")\n",
        "knn = KNeighborsClassifier(n_neighbors=100)\n",
        "gnb = GaussianNB()\n",
        "\n",
        "stack = StackingCVClassifier(classifiers=(rf, lgbm, cat, knn, gnb, lr, cat_fast),\n",
        "                            meta_classifier=xgb, cv=5,\n",
        "                            use_features_in_secondary=False,\n",
        "                            store_train_meta_features=True,\n",
        "                            shuffle=False, stratify = True, use_probas = True)\n",
        "\n",
        "#stack.fit(X_train.values, y_train.values)\n",
        "stack.fit(X.values, y.values)\n",
        "X.columns = ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8']\n",
        "y_pred = stack.predict(test_df_off)\n",
        "# print(\"Testing Accuracy \", accuracy_score(y_test, y_pred))\n",
        "# print(\"F1 score \", f1_score(y_test, y_pred, average = 'weighted'))\n",
        "# print(classification_report(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qk583pdiaydw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "outputId": "2dd6e427-2bed-4681-a0b1-981ab10ab175"
      },
      "source": [
        "#crude stacking -xgb-lgb,catb,rf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import skew\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from math import sqrt\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score\n",
        "from sklearn.model_selection import KFold\n",
        "from catboost import CatBoostClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "import gc\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB \n",
        "from sklearn.metrics import log_loss\n",
        "NFOLDS = 5\n",
        "SEED = 0\n",
        "NROWS = None\n",
        "\n",
        "training_data = pd.read_excel('/content/drive/My Drive/ML_Hackathon/ML_Hackathon/train.xlsx')\n",
        "training_data.drop('ID', axis = 1, inplace = True)\n",
        "training_data.rename(columns={'Number_Weeks_does_not used': 'Number_Weeks_does_not_used'}, inplace=True)\n",
        "\n",
        "X = training_data.drop(\"Crop_status\", axis=1)\n",
        "y = training_data[\"Crop_status\"]\n",
        "X.fillna(X[\"Number_of_Weeks_Used\"].median(), axis = 1, inplace = True)\n",
        "\n",
        "X[\"Number_of_Weeks_Used\"] = X[\"Number_of_Weeks_Used\"].astype(np.int) \n",
        "X=pd.get_dummies(X, columns=[\"Crop\",\"Soil\", \"Season\"])\n",
        "\n",
        "X.drop('Soil_clay', axis = 1, inplace = True)\n",
        "X.drop('Crop_Feed', axis = 1, inplace = True)\n",
        "X.drop('Season_3', axis = 1, inplace = True)\n",
        "\n",
        "\n",
        "test_df_off = pd.read_excel('/content/drive/My Drive/ML_Hackathon/ML_Hackathon/test.xlsx')\n",
        "test_df_off.drop('ID', axis = 1, inplace = True)\n",
        "test_df_off.rename(columns={'Number_Weeks_does_not used': 'Number_Weeks_does_not_used'}, inplace=True)\n",
        "\n",
        "test_df_off.fillna(test_df_off[\"Number_of_Weeks_Used\"].median(), axis = 1, inplace = True)\n",
        "test_df_off[\"Number_of_Weeks_Used\"] = test_df_off[\"Number_of_Weeks_Used\"].astype(np.int) \n",
        "test_df_off=pd.get_dummies(test_df_off, columns=[\"Crop\",\"Soil\", \"Season\"])\n",
        "test_df_off.drop('Soil_clay', axis = 1, inplace = True)\n",
        "test_df_off.drop('Crop_Feed', axis = 1, inplace = True)\n",
        "test_df_off.drop('Season_3', axis = 1, inplace = True)\n",
        "\n",
        "#x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, stratify = y)\n",
        "\n",
        "#whole dataset\n",
        "x_train = X\n",
        "y_train = y\n",
        "x_test = test_df_off\n",
        "ntrain = X.shape[0]\n",
        "ntest = test_df_off.shape[0]\n",
        "\n",
        "\n",
        "kf = KFold(n_splits = NFOLDS, shuffle=True, random_state=SEED)\n",
        "# ntrain = x_train.shape[0]\n",
        "# ntest = x_test.shape[0]\n",
        "\n",
        "\n",
        "class SklearnWrapper_no_rs(object):\n",
        "    def __init__(self, clf, seed=0, params=None):\n",
        "        self.clf = clf(**params)\n",
        "\n",
        "    def train(self, x_train, y_train):\n",
        "        self.clf.fit(x_train, y_train)\n",
        "\n",
        "    def predict(self, x):\n",
        "        return self.clf.predict_proba(x)\n",
        "\n",
        "class SklearnWrapper(object):\n",
        "    def __init__(self, clf, seed=0, params=None):\n",
        "        params['random_state'] = seed\n",
        "        self.clf = clf(**params)\n",
        "\n",
        "    def train(self, x_train, y_train):\n",
        "        self.clf.fit(x_train, y_train)\n",
        "\n",
        "    def predict(self, x):\n",
        "        #return self.clf.predict_proba(x)[:,1]\n",
        "        return self.clf.predict_proba(x)\n",
        "\n",
        "class CatboostWrapper(object):\n",
        "    def __init__(self, clf, seed=0, params=None):\n",
        "        params['random_seed'] = seed\n",
        "        self.clf = clf(**params)\n",
        "\n",
        "    def train(self, x_train, y_train):\n",
        "        self.clf.fit(x_train, y_train)\n",
        "\n",
        "    def predict(self, x):\n",
        "        return self.clf.predict_proba(x)[:,1]\n",
        "        \n",
        "class LightGBMWrapper(object):\n",
        "    def __init__(self, clf, seed=0, params=None):\n",
        "        params['feature_fraction_seed'] = seed\n",
        "        params['bagging_seed'] = seed\n",
        "        self.clf = clf(**params)\n",
        "\n",
        "    def train(self, x_train, y_train):\n",
        "        self.clf.fit(x_train, y_train)\n",
        "\n",
        "    def predict(self, x):\n",
        "        return self.clf.predict_proba(x)[:,1]\n",
        "\n",
        "\n",
        "class XgbWrapper(object):\n",
        "    def __init__(self, clf, seed=0, params=None):\n",
        "        self.param = params\n",
        "        self.clf = clf(**params)\n",
        "        params['seed'] = seed\n",
        "        \n",
        "        #self.nrounds = params.pop('nrounds', 250)\n",
        "\n",
        "    def train(self, x_train, y_train):\n",
        "        # dtrain = xgb.DMatrix(x_train, label=y_train)\n",
        "        # self.gbdt = xgb.train(self.param, dtrain, self.nrounds)\n",
        "        self.clf.fit(x_train, y_train)\n",
        "    def predict(self, x):\n",
        "        #return self.gbdt.predict(xgb.DMatrix(x))\n",
        "        return self.clf.predict_proba(x)[:,1]\n",
        "\n",
        "\n",
        "def get_oof(clf):\n",
        "    oof_train = np.zeros((ntrain,))\n",
        "    oof_test = np.zeros((ntest,))\n",
        "    oof_test_skf = np.empty((NFOLDS, ntest))\n",
        "\n",
        "    for i, (train_index, test_index) in enumerate(kf.split(x_train)):\n",
        "        x_tr = x_train.iloc[train_index]\n",
        "        y_tr = y_train.iloc[train_index]\n",
        "        x_te = x_train.iloc[test_index]\n",
        "\n",
        "        clf.train(x_tr, y_tr)\n",
        "\n",
        "        oof_train[test_index] = clf.predict(x_te)\n",
        "        oof_test_skf[i, :] = clf.predict(x_test)\n",
        "\n",
        "    oof_test[:] = oof_test_skf.mean(axis=0)\n",
        "    return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1)\n",
        "\n",
        "\n",
        "et_params = {\n",
        "    'n_jobs': 16,\n",
        "    'n_estimators': 10,\n",
        "    'max_features': 0.5,\n",
        "    'max_depth': 12,\n",
        "    #'min_samples_leaf': 2,\n",
        "}\n",
        "\n",
        "rf_params = {\n",
        "    'n_jobs': 16,\n",
        "    'n_estimators': 10,\n",
        "    'max_features': 0.2,\n",
        "    'max_depth': 12,\n",
        "    #'min_samples_leaf': 2,\n",
        "}\n",
        "\n",
        "xgb_params = {\n",
        "    'objective': 'multi:softprob',\n",
        "    'eta':0.1,\n",
        "    'max_depth':6,\n",
        "    'num_class':3,\n",
        "    'eval_metric':\"mlogloss\",\n",
        "    'min_child_weight': 1,\n",
        "    'subsample': 0.7,\n",
        "    'colsample_bytree': 0.7\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "# xgb_params = {\n",
        "#     'seed': 0,\n",
        "#     # 'colsample_bytree': 0.7,\n",
        "#     # 'silent': 1,\n",
        "#     # 'subsample': 0.7,\n",
        "#     # 'learning_rate': 0.07,\n",
        "#     # 'objective': 'multi:softprob',\n",
        "#     # 'max_depth': 4,\n",
        "#     # 'num_parallel_tree': 1,\n",
        "#     # 'min_child_weight': 1,\n",
        "#     # 'nrounds': 700,\n",
        "#     'num_class': 3,\n",
        "#     # 'gamma': 2.8,\n",
        "#     # 'reg_alpha':0.5, \n",
        "#     # 'reg_lambda':1\n",
        "# }\n",
        "\n",
        "catboost_params = {\n",
        "    # 'iterations': 888,\n",
        "    # 'learning_rate': 0.5,\n",
        "    # 'depth': 5,\n",
        "    # 'l2_leaf_reg': 40,\n",
        "    # 'bootstrap_type': 'Bernoulli',\n",
        "    # 'subsample': 0.7,\n",
        "    #'scale_pos_weight': 5,\n",
        "    'eval_metric': 'MultiClass',\n",
        "    # 'od_type': 'Iter',\n",
        "    # 'allow_writing_files': False,\n",
        "    'loss_function': 'MultiClass',\n",
        "    'classes_count': 3,\n",
        "    # 'random_strength': 0.9,\n",
        "    # 'boosting_type': 'Ordered'\n",
        "}\n",
        "\n",
        "lightgbm_params = {\n",
        "    # 'n_estimators':200,\n",
        "    # 'learning_rate':0.1,\n",
        "    # 'num_leaves':123,\n",
        "    # 'colsample_bytree':0.8,\n",
        "    # 'subsample':0.9,\n",
        "    # 'max_depth':15,\n",
        "    # 'reg_alpha':0.1,\n",
        "    # 'reg_lambda':0.1,\n",
        "    # 'min_split_gain':0.01,\n",
        "    # 'min_child_weight':2    \n",
        "}\n",
        "knn_params = {'n_neighbors': 100}\n",
        "\n",
        "knn = SklearnWrapper_no_rs(clf = KNeighborsClassifier, params = knn_params)\n",
        "gnb = SklearnWrapper_no_rs(clf = GaussianNB, params = {})\n",
        "\n",
        "xg = XgbWrapper(clf = XGBClassifier, seed=SEED, params=xgb_params)\n",
        "et = SklearnWrapper(clf=ExtraTreesClassifier, seed=SEED, params=et_params)\n",
        "rf = SklearnWrapper(clf=RandomForestClassifier, seed=SEED, params=rf_params)\n",
        "cb = CatboostWrapper(clf= CatBoostClassifier, seed = SEED, params=catboost_params)\n",
        "lg = LightGBMWrapper(clf = LGBMClassifier, seed = SEED, params = lightgbm_params)\n",
        "\n",
        "xg_oof_train, xg_oof_test = get_oof(xg)\n",
        "et_oof_train, et_oof_test = get_oof(et)\n",
        "rf_oof_train, rf_oof_test = get_oof(rf)\n",
        "cb_oof_train, cb_oof_test = get_oof(cb)\n",
        "lg_oof_train, lg_oof_test = get_oof(lg)\n",
        "knn_oof_train, knn_oof_test = get_oof(knn)\n",
        "gnb_oof_train, gnb_oof_test = get_oof(gnb)\n",
        "\n",
        "print(\"XG-CV: {}\".format(log_loss(y_train, xg_oof_train)))\n",
        "print(\"ET-CV: {}\".format(log_loss(y_train, et_oof_train)))\n",
        "print(\"RF-CV: {}\".format(log_loss(y_train, rf_oof_train)))\n",
        "print(\"cb-CV: {}\".format(log_loss(y_train, cb_oof_train)))\n",
        "print(\"LG-CV: {}\".format(log_loss(y_train, lg_oof_train)))\n",
        "print(\"knn-CV: {}\".format(log_loss(y_train, knn_oof_train)))\n",
        "print(\"gnb-CV: {}\".format(log_loss(y_train, gnb_oof_train)))\n",
        "\n",
        "x_train = np.concatenate(( knn_oof_train, gnb_oof_train, xg_oof_train, et_oof_train, rf_oof_train, cb_oof_train, lg_oof_train), axis=1)\n",
        "x_test = np.concatenate((knn_oof_test, gnb_oof_test, xg_oof_test, et_oof_test, rf_oof_test, cb_oof_test, lg_oof_test), axis=1)\n",
        "\n",
        "print(\"{},{}\".format(x_train.shape, x_test.shape))\n",
        "\n",
        "logistic_regression = LogisticRegression()\n",
        "logistic_regression.fit(x_train,y_train)\n",
        "\n",
        "predictions= logistic_regression.predict(x_test)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-a1df97646a16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0mxg_oof_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxg_oof_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_oof\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m \u001b[0met_oof_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0met_oof_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_oof\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0met\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0mrf_oof_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrf_oof_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_oof\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0mcb_oof_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_oof_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_oof\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-a1df97646a16>\u001b[0m in \u001b[0;36mget_oof\u001b[0;34m(clf)\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m         \u001b[0moof_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_te\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0moof_test_skf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: shape mismatch: value array of shape (16000,3) could not be broadcast to indexing result of shape (16000,)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qy_6F2oBkCuL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "fe363ed1-f2d0-407d-d7ce-edc53c15a73b"
      },
      "source": [
        "predictions\n",
        "from google.colab import files\n",
        "pd.DataFrame(predictions).to_csv('stack_cat_xgb_lgb_t2.csv') \n",
        "files.download('stack_cat_xgb_lgb_t2.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_6d9cb348-3833-4634-8bf1-ddbe47dc0078\", \"stack_cat_xgb_lgb_t2.csv\", 268893)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rxg-8PpX8Jq5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "0b7da6f0-ef3b-4b32-e2f4-23129191e28e"
      },
      "source": [
        "#crude stacking -xgb-lgb,catb,rf different twist, multiclass\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import skew\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from math import sqrt\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score\n",
        "from sklearn.model_selection import KFold\n",
        "from catboost import CatBoostClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "import gc\n",
        "import xgboost as xgb\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB \n",
        "from sklearn.metrics import log_loss\n",
        "NFOLDS = 5\n",
        "SEED = 42\n",
        "NROWS = None\n",
        "n_classes=3\n",
        "\n",
        "\n",
        "def set_input(df, is_train_set = True, median_imputation = False, dummy = False):\n",
        "  df.drop('ID', axis = 1, inplace = True)\n",
        "  df.rename(columns={'Number_Weeks_does_not used': 'Number_Weeks_does_not_used'}, inplace=True)\n",
        "\n",
        "  if is_train_set:\n",
        "    X = df.drop(\"Crop_status\", axis=1)\n",
        "    y = df[\"Crop_status\"]\n",
        "  else:\n",
        "    X = df\n",
        "\n",
        "  if median_imputation:\n",
        "    X.fillna(X[\"Number_of_Weeks_Used\"].median(), axis = 1, inplace = True)\n",
        "    X[\"Number_of_Weeks_Used\"] = X[\"Number_of_Weeks_Used\"].astype(np.int) \n",
        "\n",
        "  if dummy: \n",
        "    X=pd.get_dummies(X, columns= [\"Crop\",\"Soil\", \"Season\"])\n",
        "    X.drop('Soil_clay', axis = 1, inplace = True)\n",
        "    X.drop('Crop_Feed', axis = 1, inplace = True)\n",
        "    X.drop('Season_3', axis = 1, inplace = True)\n",
        "  \n",
        "  if is_train_set:\n",
        "    return X,y\n",
        "  else:\n",
        "    return X\n",
        "\n",
        "\n",
        "\n",
        "training_data = pd.read_excel('/content/drive/My Drive/ML_Hackathon/ML_Hackathon/train.xlsx')\n",
        "test_df_off = pd.read_excel('/content/drive/My Drive/ML_Hackathon/ML_Hackathon/test.xlsx')\n",
        "\n",
        "X, y = set_input(training_data, is_train_set = True, median_imputation = True, dummy = True)\n",
        "test_df_off= set_input(test_df_off, is_train_set = False, median_imputation = True, dummy = True)\n",
        "\n",
        "\n",
        "#x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, stratify = y)\n",
        "\n",
        "#whole dataset\n",
        "x_train = X\n",
        "y_train = y\n",
        "x_test = test_df_off\n",
        "ntrain = X.shape[0]\n",
        "ntest = test_df_off.shape[0]\n",
        "\n",
        "\n",
        "kf = KFold(n_splits = NFOLDS, shuffle=True, random_state=SEED)\n",
        "# ntrain = x_train.shape[0]\n",
        "# ntest = x_test.shape[0]\n",
        "\n",
        "\n",
        "class SklearnWrapper_no_rs(object):\n",
        "    def __init__(self, clf, seed=0, params=None):\n",
        "        self.clf = clf(**params)\n",
        "\n",
        "    def train(self, x_train, y_train):\n",
        "        self.clf.fit(x_train, y_train)\n",
        "\n",
        "    def predict(self, x):\n",
        "        return self.clf.predict_proba(x)\n",
        "\n",
        "class SklearnWrapper(object):\n",
        "    def __init__(self, clf, seed=0, params=None):\n",
        "        params['random_state'] = seed\n",
        "        self.clf = clf(**params)\n",
        "\n",
        "    def train(self, x_train, y_train):\n",
        "        self.clf.fit(x_train, y_train)\n",
        "\n",
        "    def predict_probability(self, x):\n",
        "        proba = self.clf.predict_proba(x)\n",
        "        return proba\n",
        "\n",
        "class XgbWrapper(object):\n",
        "    def __init__(self, seed=0, params=None):\n",
        "        self.param = params\n",
        "        self.param['seed'] = seed\n",
        "        self.nrounds = params.pop('nrounds', 30)\n",
        "\n",
        "    def train(self, x_train, y_train):\n",
        "        dtrain = xgb.DMatrix(x_train, label=y_train)\n",
        "        self.gbdt = xgb.train(self.param, dtrain, self.nrounds)\n",
        "\n",
        "    def predict_probability(self, x):\n",
        "        proba = self.gbdt.predict(xgb.DMatrix(x))\n",
        "        return proba\n",
        "\n",
        "\n",
        "def get_oof(clf):\n",
        "    oof_train = np.zeros((ntrain,n_classes))\n",
        "    oof_test = np.zeros((ntest,n_classes))\n",
        "    oof_test_skf = np.empty((ntest, NFOLDS*n_classes))\n",
        "\n",
        "    for i, (train_index, test_index) in enumerate(kf.split(x_train)):\n",
        "        x_tr = x_train.iloc[train_index]\n",
        "        y_tr = y_train.iloc[train_index]\n",
        "        x_te = x_train.iloc[test_index]\n",
        "\n",
        "        clf.train(x_tr, y_tr)\n",
        "\n",
        "        oof_train[test_index] = clf.predict_probability(x_te)\n",
        "        oof_test_skf[:,3*i: 3*i + 3] = clf.predict_probability(x_test)\n",
        "\n",
        "    for i in range(3):\n",
        "        oof_test[:,i] = (oof_test_skf[:,i]+oof_test_skf[:,i+3]+oof_test_skf[:,i+6]+oof_test_skf[:,i+9]+oof_test_skf[:,i+12])/5\n",
        "\n",
        "    #oof_test[:] = oof_test_skf.mean(axis=0)\n",
        "    return oof_train, oof_test\n",
        "\n",
        "\n",
        "et_params = {\n",
        "    'n_jobs': 16,\n",
        "    'n_estimators': 10,\n",
        "    'max_features': 0.5,\n",
        "    'max_depth': 12,\n",
        "    #'min_samples_leaf': 2,\n",
        "}\n",
        "\n",
        "rf_params = {\n",
        "    'n_jobs': 16,\n",
        "    'n_estimators': 10,\n",
        "    'max_features': 0.2,\n",
        "    'max_depth': 12,\n",
        "    #'min_samples_leaf': 2,\n",
        "}\n",
        "\n",
        "xgb_params = {\n",
        "    'objective': 'multi:softprob',\n",
        "    'eta':0.1,\n",
        "    'max_depth':6,\n",
        "    'num_class':3,\n",
        "    'eval_metric':\"mlogloss\",\n",
        "    'min_child_weight': 1,\n",
        "    'subsample': 0.7,\n",
        "    'colsample_bytree': 0.7\n",
        "}\n",
        "\n",
        "xg = XgbWrapper(seed=SEED, params=xgb_params)\n",
        "et = SklearnWrapper(clf=ExtraTreesClassifier, seed=SEED, params=et_params)\n",
        "rf = SklearnWrapper(clf=RandomForestClassifier, seed=SEED, params=rf_params)\n",
        "\n",
        "\n",
        "xg_oof_train, xg_oof_test = get_oof(xg)\n",
        "et_oof_train, et_oof_test = get_oof(et)\n",
        "rf_oof_train, rf_oof_test = get_oof(rf)\n",
        "\n",
        "print(\"XG-CV: {}\".format(log_loss(y_train, xg_oof_train)))\n",
        "print(\"ET-CV: {}\".format(log_loss(y_train, et_oof_train)))\n",
        "print(\"RF-CV: {}\".format(log_loss(y_train, rf_oof_train)))\n",
        "\n",
        "\n",
        "x_train = np.concatenate((xg_oof_train, et_oof_train, rf_oof_train), axis=1)\n",
        "x_test = np.concatenate((xg_oof_test, et_oof_test, rf_oof_test), axis=1)\n",
        "\n",
        "print(\"{},{}\".format(x_train.shape, x_test.shape))\n",
        "\n",
        "\n",
        "dtrain = xgb.DMatrix(x_train, label=y_train)\n",
        "dtest = xgb.DMatrix(x_test)\n",
        "\n",
        "xgb_params = {\n",
        "    'objective': 'multi:softprob',\n",
        "    'eta':0.1,\n",
        "    'max_depth':2,\n",
        "    'num_class':3,\n",
        "    'eval_metric':\"mlogloss\",\n",
        "    'min_child_weight': 1,\n",
        "    'subsample': 0.7,\n",
        "    'colsample_bytree': 0.7\n",
        "}\n",
        "\n",
        "res = xgb.cv(xgb_params, dtrain, num_boost_round=50, nfold=5, seed=SEED,\n",
        "             early_stopping_rounds=10, show_stdv=True)\n",
        "\n",
        "best_nrounds = res.shape[0] - 1\n",
        "cv_mean = res.iloc[-1, 0]\n",
        "cv_std = res.iloc[-1, 1]\n",
        "\n",
        "\n",
        "print('Ensemble-CV: {0}+{1}'.format(cv_mean, cv_std))\n",
        "gbdt = xgb.train(xgb_params, dtrain, best_nrounds)\n",
        "\n",
        "out_df = pd.DataFrame(gbdt.predict(dtest))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "XG-CV: 0.4474844187230523\n",
            "ET-CV: 0.4518112694054113\n",
            "RF-CV: 0.4703990063996262\n",
            "(80000, 9),(35000, 9)\n",
            "Ensemble-CV: 0.42851819999999996+0.0007033864940414933\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pTlW2RdTT5F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "c2873330-5061-49da-b25e-1ba62cff883d"
      },
      "source": [
        "predictions\n",
        "from google.colab import files\n",
        "pd.DataFrame(predictions).to_csv('manual_stack_logloss_3.csv') \n",
        "files.download('manual_stack_logloss_3.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_8aca211f-1fc3-4841-a50b-c47a5dddfcfc\", \"manual_stack_logloss_3.csv\", 268893)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gMu54QcVN45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "90b77dec-eee9-4ef0-f6b0-df5fb0eaf558"
      },
      "source": [
        "import numpy as np  # linear algebra\n",
        "import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from sklearn.model_selection import train_test_split\n",
        "from xgboost.sklearn import XGBClassifier\n",
        "import xgboost as xgb\n",
        "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import log_loss\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "from subprocess import check_output\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Stacking concept as from https://github.com/vecxoz/vecstack\n",
        "# We want to predict train and test sets with some 1-st level model(s), and then use this predictions as features for 2-nd level model.\n",
        "# Any model can be used as 1-st level model or 2-nd level model.\n",
        "# To avoid overfitting (for train set) we use cross-validation technique and in each fold we predict out-of-fold part of train set.\n",
        "# The common practice is to use from 3 to 10 folds.\n",
        "# In each fold we predict full test set, so after completion of all folds we need to find mean (mode) of all test set predictions made in each fold.\n",
        "# As an example we look at stacking implemented with single 1-st level model and 3-fold cross-validation.\n",
        "# We can repeat this cycle using other 1-st level models to get more features for 2-nd level model.\n",
        "\n",
        "class SklearnWrapper(object):\n",
        "    def __init__(self, clf, seed=0, params=None):\n",
        "        params['random_state'] = seed\n",
        "        self.clf = clf(**params)\n",
        "        self.classes_= None\n",
        "\n",
        "    def fit(self, x_train, y_train):\n",
        "        self.clf.fit(x_train, y_train)\n",
        "        self.classes_ = self.clf.classes_\n",
        "\n",
        "    def predict_proba(self, x):\n",
        "        proba = self.clf.predict_proba(x)\n",
        "        return proba\n",
        "\n",
        "    def get_name(self):\n",
        "        return self.clf.__class__.__name__\n",
        "\n",
        "class XgbWrapper(object):\n",
        "    def __init__(self, seed=0, params=None):\n",
        "        self.param = params\n",
        "        self.param['seed'] = seed\n",
        "        self.nrounds = params.pop('nrounds', 30)\n",
        "        self.training_data = None\n",
        "        self.classes_ = None\n",
        "\n",
        "    def fit(self, x_train, y_train):\n",
        "        dtrain = xgb.DMatrix(x_train, label=y_train)\n",
        "        self.training_data = dtrain\n",
        "        self.classes_ = [int(x) for x in list(set(self.training_data.get_label())) if x.dtype == 'float32']\n",
        "        self.gbdt = xgb.train(self.param, dtrain, self.nrounds, verbose_eval=False)\n",
        "\n",
        "    def predict_proba(self, x):\n",
        "        proba = self.gbdt.predict(xgb.DMatrix(x))\n",
        "        return proba\n",
        "\n",
        "    def get_name(self):\n",
        "        return 'XGBClassifier'\n",
        "\n",
        "class EnsembleStacking:\n",
        "    def __init__(self, X_train, y_train, X_test, base_models, stacker, cv):\n",
        "        self._X_train = X_train\n",
        "        self._y_train = y_train\n",
        "        self._X_test = X_test\n",
        "        self._base_models = base_models\n",
        "        self._stacker = stacker\n",
        "        self._cv = cv\n",
        "        self._correlations = pd.DataFrame()\n",
        "\n",
        "    def get_correlations(self):\n",
        "        return self._correlations\n",
        "\n",
        "    #get out-of-fold predictions\n",
        "    def get_oof(self, clf, X_train_oof, y_train_oof, X_test_oof):\n",
        "\n",
        "        clf.fit(X_train_oof, y_train_oof)\n",
        "        preds_train = clf.predict_proba(X_test_oof)\n",
        "        preds_test = clf.predict_proba(self._X_test)#use test set\n",
        "\n",
        "        return preds_train, preds_test\n",
        "\n",
        "    def fit_and_predict_proba(self):\n",
        "\n",
        "        stacking_predictions_training = pd.DataFrame()\n",
        "        stacking_predictions_test = pd.DataFrame()\n",
        "        stacking_predictions_oof_avg = {}\n",
        "\n",
        "        # in my words, per base model do the following.\n",
        "        # split the data according to the cv (cross validation) parameter. fit the base model\n",
        "        # and predict probabilities for the out-of-fold share of the cross validation.\n",
        "        # take these probabilities for each out of fold prediction, they will sum up to what\n",
        "        # amounts a full prediction from within the training set. as you predict the out-of-fold\n",
        "        # samples, use the same fitted model to predict probabilities of the complete test set. once\n",
        "        # you finished your cross validation (after n times), average the n test set predictions.\n",
        "        # do these steps for each of the m base models and you receive m predictions of training\n",
        "        # data (made up from the n-fold cross validation) and m averaged test data predictions.\n",
        "        # because we calculate probabilities for l classes, each training prediction contains\n",
        "        # m times l columns, as does the test prediction. this is all you need to train the\n",
        "        # final model and receive a test prediction with l columns.\n",
        "\n",
        "        last_feature = ''\n",
        "        label_len_for_corr = []\n",
        "        for i, clf in enumerate(self._base_models):\n",
        "            stacking_predictions_oof_aggr = pd.DataFrame()\n",
        "            skf = StratifiedKFold(n_splits=self._cv, random_state=0, shuffle=True)\n",
        "            counter = 0\n",
        "            for train_index, test_index in skf.split(self._X_train, self._y_train):\n",
        "                # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "                if self._X_train.__class__.__name__ == 'DataFrame':\n",
        "                    X_train_oof, X_test_oof = self._X_train.iloc[train_index], self._X_train.iloc[test_index]\n",
        "                    y_train_oof, y_test_oof = self._y_train.iloc[train_index], self._y_train.iloc[test_index]\n",
        "                else:\n",
        "                    X_train_oof, X_test_oof = self._X_train[train_index], self._X_train[test_index]\n",
        "                    y_train_oof, y_test_oof = self._y_train[train_index], self._y_train[test_index]\n",
        "\n",
        "                # collect and append the predictions\n",
        "                clf = self._base_models[i]\n",
        "                # print('Fitting model',  '...', clf.__class__.__name__, repr(i))\n",
        "                preds_train, preds_test = self.get_oof(clf=clf, X_train_oof=X_train_oof, y_train_oof=y_train_oof, X_test_oof=X_test_oof)\n",
        "\n",
        "                print(log_loss(y_true=y_test_oof, y_pred=preds_train))\n",
        "\n",
        "                preds_oof_df = pd.DataFrame()\n",
        "                for j, label in enumerate(clf.classes_):\n",
        "                    preds_oof_df[clf.get_name() + repr(i) + '_' + repr(label)] = preds_train[:, j]\n",
        "                    last_feature = clf.get_name() + repr(i) + '_' + repr(label)\n",
        "                preds_oof_df['index'] = test_index  # keep order of entries with an index\n",
        "                stacking_predictions_oof_aggr = stacking_predictions_oof_aggr.append(preds_oof_df)\n",
        "\n",
        "                # since our k-fold stacking predictions will have only three columns, also our test set needs to change\n",
        "                # save each test set prediction fitted from all training data, later averaged\n",
        "                stacking_predictions_oof_avg[counter] = pd.DataFrame()\n",
        "                for j, label in enumerate(clf.classes_):\n",
        "                    stacking_predictions_oof_avg[counter][clf.get_name() + repr(i) + '_' + repr(label)] = preds_test[:, j]\n",
        "                counter += 1\n",
        "\n",
        "            # add predict_proba columns to final prediction features\n",
        "            stacking_predictions_oof_aggr = stacking_predictions_oof_aggr.sort_values(['index'], ascending=[1])\n",
        "            stacking_predictions_oof_aggr.drop(['index'], axis=1, inplace=True)\n",
        "            for j, column in enumerate(stacking_predictions_oof_aggr):\n",
        "                stacking_predictions_training[column] = stacking_predictions_oof_aggr[column]\n",
        "            #print('These should be equal in rows:', stacking_X_train.shape, stacking_predictions_kfold.shape)\n",
        "\n",
        "            # add test set predictions average to final prediction features\n",
        "            panel = pd.Panel.to_frame(stacking_predictions_oof_avg)\n",
        "            df_test_prediction_avg = panel.mean(axis=0)\n",
        "            #print('These should be equal in rows:', stacking_X_test.shape, df_test_prediction_avg.shape)\n",
        "            for j, column in enumerate(df_test_prediction_avg):\n",
        "                stacking_predictions_test[column] = df_test_prediction_avg[column]\n",
        "\n",
        "        # train a second-layer model on these predictions\n",
        "        if self._y_train.__class__.__name__ == 'Series':\n",
        "            stacking_predictions_training['target'] = self._y_train.as_matrix()\n",
        "        else:\n",
        "            stacking_predictions_training['target'] = self._y_train\n",
        "\n",
        "        self._stacker.fit(stacking_predictions_training.ix[:, :last_feature], stacking_predictions_training['target'])\n",
        "        preds = self._stacker.predict_proba(stacking_predictions_test)\n",
        "        solution = pd.DataFrame()\n",
        "        for index, label in enumerate(self._stacker.classes_):\n",
        "            label_len_for_corr.append(repr(label))\n",
        "            solution[label] = preds[:, index]\n",
        "\n",
        "        # calculate correlation matrix\n",
        "        temp_num_classes = int(len(stacking_predictions_training.columns) / len(self._base_models))\n",
        "        temp_column_name = []\n",
        "        temp_corr_mat = {}\n",
        "        for l in range(0, temp_num_classes):\n",
        "            temp_corr_df = pd.DataFrame()\n",
        "            for k, clf in enumerate(self._base_models):\n",
        "                # iterate over linked columns\n",
        "                temp_corr_df[self._base_models[k].get_name()] = stacking_predictions_training.ix[:,l + (temp_num_classes * k)]\n",
        "            # calculate correlation matrix for each label, then average the correlation matrices\n",
        "            temp_corr_mat[l] = pd.DataFrame(np.corrcoef(temp_corr_df.T))\n",
        "        for k, clf in enumerate(self._base_models):\n",
        "            # add name to columns, index\n",
        "            temp_column_name.append(self._base_models[k].get_name())\n",
        "        temp_panel = pd.Panel(temp_corr_mat)\n",
        "        self._correlations = temp_panel.mean(axis=0)\n",
        "        self._correlations.columns = temp_column_name\n",
        "        self._correlations.index = temp_column_name\n",
        "\n",
        "        return solution\n",
        "# specify the different parameter and models\n",
        "et_params = {\n",
        "    'n_jobs': 4,\n",
        "    'n_estimators': 10,\n",
        "    'max_features': 0.5,\n",
        "    'max_depth': 12,\n",
        "    #'min_samples_leaf': 2,\n",
        "}\n",
        "\n",
        "rf_params = {\n",
        "    'n_jobs': 4,\n",
        "    'n_estimators': 10,\n",
        "    'max_features': 0.2,\n",
        "    'max_depth': 12,\n",
        "    #'min_samples_leaf': 2,\n",
        "}\n",
        "\n",
        "xgb_params = {\n",
        "    'objective': 'multi:softprob',\n",
        "    'eta':0.1,\n",
        "    'max_depth':6,\n",
        "    'num_class':3,\n",
        "    'eval_metric':\"mlogloss\",\n",
        "    'min_child_weight': 1,\n",
        "    'subsample': 0.7,\n",
        "    'colsample_bytree': 0.7\n",
        "}\n",
        "\n",
        "rd_params={\n",
        "    'alpha': 10\n",
        "}\n",
        "\n",
        "lr_params={\n",
        "    'random_state': 1\n",
        "}\n",
        "\n",
        "training_data = pd.read_excel('/content/drive/My Drive/ML_Hackathon/ML_Hackathon/train.xlsx')\n",
        "test_df_off = pd.read_excel('/content/drive/My Drive/ML_Hackathon/ML_Hackathon/test.xlsx')\n",
        "\n",
        "X, y = set_input(training_data, is_train_set = True, median_imputation = True, dummy = True)\n",
        "test_df_off= set_input(test_df_off, is_train_set = False, median_imputation = True, dummy = True)\n",
        "\n",
        "stacking_X_train, stacking_X_test, stacking_y_train, stacking_y_test = train_test_split(X, y, test_size=0.33, random_state=42, stratify = y)\n",
        "\n",
        "\n",
        "xg = XgbWrapper(seed=0, params=xgb_params)\n",
        "et = SklearnWrapper(clf=ExtraTreesClassifier, seed=0, params=et_params)\n",
        "rf = SklearnWrapper(clf=RandomForestClassifier, seed=0, params=rf_params)\n",
        "lr = SklearnWrapper(clf=LogisticRegression, seed=0, params=lr_params)\n",
        "\n",
        "base_models = [xg, et, rf, lr]\n",
        "\n",
        "final_model = XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
        "                            gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=6,\n",
        "                            min_child_weight=1, missing=None, n_estimators=310, nthread=-1,\n",
        "                            objective='multi:softprob', reg_alpha=0, reg_lambda=1,\n",
        "                            scale_pos_weight=1, seed=0, silent=True, subsample=1)\n",
        "\n",
        "ensemble = EnsembleStacking(X_train=stacking_X_train, y_train=stacking_y_train, X_test=stacking_X_test,\n",
        "                            base_models=base_models, stacker=final_model, cv=5)\n",
        "\n",
        "solution = ensemble.fit_and_predict_proba()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.45242206604365925\n",
            "0.44643163191008645\n",
            "0.44745660711726204\n",
            "0.44856993765083714\n",
            "0.4441071990682785\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-3474915831f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    249\u001b[0m                             base_models=base_models, stacker=final_model, cv=5)\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m \u001b[0msolution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensemble\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_and_predict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-39-3474915831f8>\u001b[0m in \u001b[0;36mfit_and_predict_proba\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0;31m# add test set predictions average to final prediction features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m             \u001b[0mpanel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPanel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstacking_predictions_oof_avg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m             \u001b[0mdf_test_prediction_avg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpanel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0;31m#print('These should be equal in rows:', stacking_X_test.shape, df_test_prediction_avg.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: type object 'Panel' has no attribute 'to_frame'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqjTmiy8NSBX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "d9633800-c917-4bcc-f9ca-eb3ee6690cc8"
      },
      "source": [
        "training_data.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Insects</th>\n",
              "      <th>Crop</th>\n",
              "      <th>Soil</th>\n",
              "      <th>Category_of_Toxicant</th>\n",
              "      <th>Does_count</th>\n",
              "      <th>Number_of_Weeks_Used</th>\n",
              "      <th>Number_Weeks_does_not_used</th>\n",
              "      <th>Season</th>\n",
              "      <th>Crop_status</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>188</td>\n",
              "      <td>Feed</td>\n",
              "      <td>clay</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>209</td>\n",
              "      <td>Feed</td>\n",
              "      <td>clay</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>257</td>\n",
              "      <td>Feed</td>\n",
              "      <td>clay</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>257</td>\n",
              "      <td>Feed</td>\n",
              "      <td>silt</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>342</td>\n",
              "      <td>Feed</td>\n",
              "      <td>clay</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Insects  Crop  Soil  ...  Number_Weeks_does_not_used  Season  Crop_status\n",
              "0      188  Feed  clay  ...                           0       1            0\n",
              "1      209  Feed  clay  ...                           0       2            1\n",
              "2      257  Feed  clay  ...                           0       2            1\n",
              "3      257  Feed  silt  ...                           0       2            1\n",
              "4      342  Feed  clay  ...                           0       2            1\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTo0l3pUNddn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "84a9eec4-b1f9-4d9a-9286-36c90572b1fa"
      },
      "source": [
        "training_data_clean.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Insects</th>\n",
              "      <th>Category_of_Toxicant</th>\n",
              "      <th>Does_count</th>\n",
              "      <th>Number_of_Weeks_Used</th>\n",
              "      <th>Number_Weeks_does_not_used</th>\n",
              "      <th>Crop_Food</th>\n",
              "      <th>Soil_silt</th>\n",
              "      <th>Season_1</th>\n",
              "      <th>Season_2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>188</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>209</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>257</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>257</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>342</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Insects  Category_of_Toxicant  Does_count  ...  Soil_silt  Season_1  Season_2\n",
              "0      188                     1           0  ...          0         1         0\n",
              "1      209                     1           0  ...          0         0         1\n",
              "2      257                     1           0  ...          0         0         1\n",
              "3      257                     1           0  ...          1         0         1\n",
              "4      342                     1           0  ...          0         0         1\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9HgewRkNiCg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "outputId": "206d55a8-0988-42b4-afa9-9b57b4a3ab26"
      },
      "source": [
        "test_df_off"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Insects</th>\n",
              "      <th>Crop</th>\n",
              "      <th>Soil</th>\n",
              "      <th>Category_of_Toxicant</th>\n",
              "      <th>Does_count</th>\n",
              "      <th>Number_of_Weeks_Used</th>\n",
              "      <th>Number_Weeks_does_not_used</th>\n",
              "      <th>Season</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>188</td>\n",
              "      <td>Feed</td>\n",
              "      <td>silt</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>410</td>\n",
              "      <td>Feed</td>\n",
              "      <td>silt</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>626</td>\n",
              "      <td>Feed</td>\n",
              "      <td>clay</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>731</td>\n",
              "      <td>Feed</td>\n",
              "      <td>clay</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>789</td>\n",
              "      <td>Food</td>\n",
              "      <td>clay</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34995</th>\n",
              "      <td>677</td>\n",
              "      <td>Food</td>\n",
              "      <td>silt</td>\n",
              "      <td>2</td>\n",
              "      <td>40</td>\n",
              "      <td>27</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34996</th>\n",
              "      <td>731</td>\n",
              "      <td>Food</td>\n",
              "      <td>silt</td>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "      <td>8</td>\n",
              "      <td>20</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34997</th>\n",
              "      <td>732</td>\n",
              "      <td>Food</td>\n",
              "      <td>silt</td>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>20</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34998</th>\n",
              "      <td>731</td>\n",
              "      <td>Food</td>\n",
              "      <td>silt</td>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "      <td>31</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34999</th>\n",
              "      <td>731</td>\n",
              "      <td>Food</td>\n",
              "      <td>silt</td>\n",
              "      <td>2</td>\n",
              "      <td>15</td>\n",
              "      <td>8</td>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>35000 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Insects  Crop  ... Number_Weeks_does_not_used  Season\n",
              "0          188  Feed  ...                          0       2\n",
              "1          410  Feed  ...                          0       2\n",
              "2          626  Feed  ...                          0       2\n",
              "3          731  Feed  ...                          0       2\n",
              "4          789  Food  ...                          0       1\n",
              "...        ...   ...  ...                        ...     ...\n",
              "34995      677  Food  ...                          3       1\n",
              "34996      731  Food  ...                         20       3\n",
              "34997      732  Food  ...                         20       2\n",
              "34998      731  Food  ...                          2       2\n",
              "34999      731  Food  ...                         16       1\n",
              "\n",
              "[35000 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBcEVekbNka9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "outputId": "929334eb-6b84-48c6-8160-1cb70ae49180"
      },
      "source": [
        "test_df_off_clean"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Insects</th>\n",
              "      <th>Category_of_Toxicant</th>\n",
              "      <th>Does_count</th>\n",
              "      <th>Number_of_Weeks_Used</th>\n",
              "      <th>Number_Weeks_does_not_used</th>\n",
              "      <th>Crop_Food</th>\n",
              "      <th>Soil_silt</th>\n",
              "      <th>Season_1</th>\n",
              "      <th>Season_2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>188</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>410</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>626</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>731</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>789</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34995</th>\n",
              "      <td>677</td>\n",
              "      <td>2</td>\n",
              "      <td>40</td>\n",
              "      <td>27</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34996</th>\n",
              "      <td>731</td>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "      <td>8</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34997</th>\n",
              "      <td>732</td>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34998</th>\n",
              "      <td>731</td>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "      <td>31</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34999</th>\n",
              "      <td>731</td>\n",
              "      <td>2</td>\n",
              "      <td>15</td>\n",
              "      <td>8</td>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>35000 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Insects  Category_of_Toxicant  Does_count  ...  Soil_silt  Season_1  Season_2\n",
              "0          188                     1           0  ...          1         0         1\n",
              "1          410                     1           0  ...          1         0         1\n",
              "2          626                     1           0  ...          0         0         1\n",
              "3          731                     1           0  ...          0         0         1\n",
              "4          789                     1           0  ...          0         1         0\n",
              "...        ...                   ...         ...  ...        ...       ...       ...\n",
              "34995      677                     2          40  ...          1         1         0\n",
              "34996      731                     2          10  ...          1         0         0\n",
              "34997      732                     2          10  ...          1         0         1\n",
              "34998      731                     2          10  ...          1         0         1\n",
              "34999      731                     2          15  ...          1         1         0\n",
              "\n",
              "[35000 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    }
  ]
}